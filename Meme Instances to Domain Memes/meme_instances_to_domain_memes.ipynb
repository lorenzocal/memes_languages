{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "rlA1ibbuPNOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#dataset_path = \"/content/drive/MyDrive/Memes dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLRSDsZ9PQ06",
        "outputId": "1bd992f9-263a-47de-af3e-3e521776e5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define variables to deal with Gemini's request time limit"
      ],
      "metadata": {
        "id": "JBcn9vQsOfd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "global TIME_LAST_REQUEST\n",
        "global TIME_BETWEEN_REQUESTS\n",
        "\n",
        "TIME_LAST_REQUEST = datetime.now()\n",
        "TIME_BETWEEN_REQUESTS = 4.5 #seconds\n",
        "# Gemini 1.5 Flash -> 15 RPM (1 req. each 4 s)"
      ],
      "metadata": {
        "id": "T8fXZRegOX0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "q5VqICiQSJmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install frame-semantic-transformer\n",
        "!pip install cnocr[ort-gpu]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qov3dq02QhP",
        "outputId": "b150165b-6563-44f1-bed9-6a8625b729ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: frame-semantic-transformer in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: nlpaug<2.0.0,>=1.1.11 in /usr/local/lib/python3.11/dist-packages (from frame-semantic-transformer) (1.1.11)\n",
            "Requirement already satisfied: nltk<4.0,>=3.7 in /usr/local/lib/python3.11/dist-packages (from frame-semantic-transformer) (3.9.1)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.20.1 in /usr/local/lib/python3.11/dist-packages (from frame-semantic-transformer) (3.20.3)\n",
            "Collecting pytorch-lightning<2.0.0,>=1.6.2 (from frame-semantic-transformer)\n",
            "  Using cached pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.97 in /usr/local/lib/python3.11/dist-packages (from frame-semantic-transformer) (0.1.99)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from frame-semantic-transformer) (4.67.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from frame-semantic-transformer) (4.47.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.32.3)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0,>=3.7->frame-semantic-transformer) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0,>=3.7->frame-semantic-transformer) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0,>=3.7->frame-semantic-transformer) (2024.11.6)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (2.5.1+cu121)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (6.0.2)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (2024.10.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.6.1)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (0.11.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.18.0->frame-semantic-transformer) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.18.0->frame-semantic-transformer) (0.27.1)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.18.0->frame-semantic-transformer) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.18.0->frame-semantic-transformer) (0.5.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (3.11.11)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (4.12.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.6.0.post0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (3.0.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (1.7.1)\n",
            "Using cached pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "Installing collected packages: pytorch-lightning\n",
            "  Attempting uninstall: pytorch-lightning\n",
            "    Found existing installation: pytorch-lightning 2.5.0.post0\n",
            "    Uninstalling pytorch-lightning-2.5.0.post0:\n",
            "      Successfully uninstalled pytorch-lightning-2.5.0.post0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cnocr 2.3.1 requires pytorch-lightning>=2.0.0, but you have pytorch-lightning 1.9.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pytorch-lightning-1.9.5\n",
            "Requirement already satisfied: cnocr[ort-gpu] in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (8.1.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (1.26.4)\n",
            "Collecting pytorch-lightning>=2.0.0 (from cnocr[ort-gpu])\n",
            "  Using cached pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (0.19.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (1.6.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (11.1.0)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (1.17.0)\n",
            "Requirement already satisfied: cnstd>=1.2.5.1 in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (1.2.5.2)\n",
            "Requirement already satisfied: rapidocr-onnxruntime<1.4 in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (1.3.25)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.11/dist-packages (from cnocr[ort-gpu]) (1.20.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (6.0.2)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (1.3.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (2.2.2)\n",
            "Requirement already satisfied: opencv-python>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (4.10.0.84)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (2.0.6)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (1.3.0.post6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (0.27.1)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (from cnstd>=1.2.5.1->cnocr[ort-gpu]) (8.3.67)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (0.11.9)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from rapidocr-onnxruntime<1.4->cnocr[ort-gpu]) (1.17.0)\n",
            "Requirement already satisfied: onnxruntime>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from rapidocr-onnxruntime<1.4->cnocr[ort-gpu]) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->cnocr[ort-gpu]) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->cnocr[ort-gpu]) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->cnocr[ort-gpu]) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->cnocr[ort-gpu]) (3.20.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->cnocr[ort-gpu]) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->cnocr[ort-gpu]) (24.12.23)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->cnocr[ort-gpu]) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->cnocr[ort-gpu]) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->cnocr[ort-gpu]) (4.3.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->cnocr[ort-gpu]) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->cnocr[ort-gpu]) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->cnocr[ort-gpu]) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->cnocr[ort-gpu]) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->cnocr[ort-gpu]) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->cnocr[ort-gpu]) (75.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (3.11.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->cnocr[ort-gpu]) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->cnocr[ort-gpu]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->cnocr[ort-gpu]) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->cnocr[ort-gpu]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->cnocr[ort-gpu]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->cnocr[ort-gpu]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->cnocr[ort-gpu]) (2024.12.14)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu->cnocr[ort-gpu]) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->cnocr[ort-gpu]) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cnstd>=1.2.5.1->cnocr[ort-gpu]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cnstd>=1.2.5.1->cnocr[ort-gpu]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cnstd>=1.2.5.1->cnocr[ort-gpu]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cnstd>=1.2.5.1->cnocr[ort-gpu]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cnstd>=1.2.5.1->cnocr[ort-gpu]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->cnstd>=1.2.5.1->cnocr[ort-gpu]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->cnstd>=1.2.5.1->cnocr[ort-gpu]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->cnstd>=1.2.5.1->cnocr[ort-gpu]) (2024.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics->cnstd>=1.2.5.1->cnocr[ort-gpu]) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->cnstd>=1.2.5.1->cnocr[ort-gpu]) (2.0.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->cnocr[ort-gpu]) (1.18.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->cnocr[ort-gpu]) (5.0.2)\n",
            "Using cached pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "Installing collected packages: pytorch-lightning\n",
            "  Attempting uninstall: pytorch-lightning\n",
            "    Found existing installation: pytorch-lightning 1.9.5\n",
            "    Uninstalling pytorch-lightning-1.9.5:\n",
            "      Successfully uninstalled pytorch-lightning-1.9.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "frame-semantic-transformer 0.10.0 requires pytorch-lightning<2.0.0,>=1.6.2, but you have pytorch-lightning 2.5.0.post0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pytorch-lightning-2.5.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "import re\n",
        "import requests\n",
        "import torch\n",
        "import json\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "from PIL import Image, ImageDraw, ImageFilter\n",
        "from frame_semantic_transformer import FrameSemanticTransformer\n",
        "from cnocr import CnOcr\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "iHaCF68kSRTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load models"
      ],
      "metadata": {
        "id": "gUtAqk9GSeJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_captioning_model():\n",
        "\n",
        "  global model, processor, device, torch_dtype\n",
        "\n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "  torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "  model = AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-large\", torch_dtype=torch_dtype, trust_remote_code=True).to(device)\n",
        "  processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large\", trust_remote_code=True)\n",
        "\n",
        "load_captioning_model()\n",
        "\n",
        "def load_llm():\n",
        "\n",
        "  global large_language_model\n",
        "\n",
        "  genai.configure(api_key=\"\")\n",
        "  large_language_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "load_llm()\n",
        "\n",
        "def load_frame_extractor():\n",
        "\n",
        "  global frame_transformer\n",
        "\n",
        "  frame_transformer = FrameSemanticTransformer()\n",
        "\n",
        "load_frame_extractor()\n",
        "\n",
        "def load_chinese_ocr():\n",
        "\n",
        "  global ocr\n",
        "\n",
        "  ocr = CnOcr(det_model_name='ch_PP-OCRv4_det', rec_model_name='ch_PP-OCRv4')\n",
        "\n",
        "load_chinese_ocr()\n"
      ],
      "metadata": {
        "id": "chd01mdrSifR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fda3fae-5c4a-4064-d361-1c568fbec73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract superimposed text"
      ],
      "metadata": {
        "id": "u-PIXN1VT4OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ocr_region(image):\n",
        "\n",
        "    prompt = \"<OCR_WITH_REGION>\"\n",
        "\n",
        "\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        pixel_values=inputs[\"pixel_values\"],\n",
        "        max_new_tokens=4096,\n",
        "        num_beams=3,\n",
        "        do_sample=False\n",
        "    )\n",
        "\n",
        "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "\n",
        "    parsed_answer = processor.post_process_generation(generated_text, task=prompt, image_size=(image.width, image.height))\n",
        "\n",
        "    labels = parsed_answer[prompt]['labels']\n",
        "\n",
        "    text = \" \".join(re.sub(r\"</?[^>]+>\", \"\", s) for s in labels)\n",
        "\n",
        "    return text, parsed_answer[prompt]['quad_boxes']\n",
        "\n",
        "def is_chinese(text):\n",
        "    \"\"\"\n",
        "    Check if the text contains Chinese characters (Simplified or Traditional).\n",
        "    \"\"\"\n",
        "    # Unicode ranges for Chinese characters\n",
        "    chinese_pattern = re.compile(r'[\\u4e00-\\u9fff]')\n",
        "    return bool(chinese_pattern.search(text))\n",
        "\n",
        "# Define a different text extraction for Chinese memes (Florence doesn't correctly retrieve Chinese text)\n",
        "def ocr_chinese(image_path):\n",
        "\n",
        "  output = ocr.ocr(image_path)\n",
        "  extracted_text = \"\"\n",
        "  for out in output:\n",
        "    sub_text = out['text']\n",
        "    # Exclude the creator of the meme from the text\n",
        "    if sub_text[0] != \"@\" and is_chinese(sub_text):\n",
        "      extracted_text += sub_text + \" \"\n",
        "\n",
        "  return extracted_text"
      ],
      "metadata": {
        "id": "-P5ST4X7RbjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text masking"
      ],
      "metadata": {
        "id": "O3G8mHraUcTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_image(image, bounds, blur_radius=10):\n",
        "\n",
        "  blurred_image = image.filter(ImageFilter.GaussianBlur(blur_radius))\n",
        "\n",
        "  mask = Image.new(\"L\", image.size, 0)\n",
        "  mask_draw = ImageDraw.Draw(mask)\n",
        "\n",
        "  for quad in bounds:\n",
        "    # Draw each quadrilateral on the mask\n",
        "    polygon = [(quad[i], quad[i + 1]) for i in range(0, len(quad), 2)]\n",
        "    mask_draw.polygon(polygon, fill=255)\n",
        "\n",
        "  # Composite the blurred image over the original using the mask\n",
        "  image.paste(blurred_image, (0, 0), mask)\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "2KNBrlFZPvcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caption generation"
      ],
      "metadata": {
        "id": "dIrgxs6cUiKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption(image):\n",
        "\n",
        "    prompt = \"<MORE_DETAILED_CAPTION>\"\n",
        "\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device, torch_dtype)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        pixel_values=inputs[\"pixel_values\"],\n",
        "        max_new_tokens=4096,\n",
        "        num_beams=3,\n",
        "        do_sample=False\n",
        "    )\n",
        "\n",
        "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "\n",
        "    parsed_answer = processor.post_process_generation(generated_text, task=prompt, image_size=(image.width, image.height))\n",
        "\n",
        "    return parsed_answer[prompt]"
      ],
      "metadata": {
        "id": "jJ7TVhO2V35e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explaination generation"
      ],
      "metadata": {
        "id": "l1hBL89sUtaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_meaning(text, caption):\n",
        "\n",
        "    global TIME_LAST_REQUEST, TIME_BETWEEN_REQUESTS\n",
        "\n",
        "    current_time = datetime.now()\n",
        "    time_from_last_request = current_time - TIME_LAST_REQUEST\n",
        "\n",
        "    if time_from_last_request.seconds < TIME_BETWEEN_REQUESTS:\n",
        "        time_to_wait = TIME_BETWEEN_REQUESTS - time_from_last_request.seconds\n",
        "        time.sleep(time_to_wait)\n",
        "\n",
        "    TIME_LAST_REQUEST = datetime.now()\n",
        "\n",
        "    response = large_language_model.generate_content(\n",
        "    f\"Explain the meaning of this meme given the image description: '{caption}' and the superimposed text: '{text}'.\",\n",
        "    generation_config=genai.types.GenerationConfig(\n",
        "        #candidate_count=1,\n",
        "        #stop_sequences=[\"x\"],\n",
        "        #max_output_tokens=100,\n",
        "        temperature=1.5,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "wZfAeRAxZdsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full pipeline"
      ],
      "metadata": {
        "id": "mdLam7JAU8Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []"
      ],
      "metadata": {
        "id": "2Rhfgi_55i8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def instance_already_processed(results, meme_name, language, instance):\n",
        "    for result in results:\n",
        "        if result[\"Meme name\"] == meme_name and result[\"Language\"] == language and result[\"Instance\"] == instance:\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "GGntz-PY4ubn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder = \"/content/drive/MyDrive/Dataset\"\n",
        "\n",
        "subfolders = [item for item in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, item))]\n",
        "total_memes = len(subfolders)\n",
        "counter = 0\n",
        "\n",
        "\n",
        "# Loop through all meme folders\n",
        "for meme_folder in os.listdir(root_folder):\n",
        "    meme_path = os.path.join(root_folder, meme_folder)\n",
        "\n",
        "    if os.path.isdir(meme_path):  # Check if it's a folder\n",
        "        counter += 1\n",
        "        print(f\"\\nProcessing meme: {meme_folder}      {counter}/{total_memes}\")\n",
        "        # Loop through the 'English', 'French', and 'Chinese' subfolders\n",
        "        for language_folder in ['English', 'French', 'Chinese']:\n",
        "            language_path = os.path.join(meme_path, language_folder)\n",
        "\n",
        "            if os.path.isdir(language_path):  # Check if the language folder exists\n",
        "                print(f\"\\tProcessing language: {language_folder}\")\n",
        "                # Loop through all images in the language folder\n",
        "                for instance in os.listdir(language_path):\n",
        "                    instance_path = os.path.join(language_path, instance)\n",
        "\n",
        "                    if os.path.isfile(instance_path) and instance.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\", \".tiff\")):  # Check if it's a file (image)\n",
        "                        # Perform your operation on each image\n",
        "                        if instance_already_processed(results, meme_folder, language_folder, instance):\n",
        "                          print(f\"\\t\\tInstance {instance} already processed.\")\n",
        "                          continue\n",
        "                        else:\n",
        "                          print(f\"\\t\\tProcessing instance: {instance}\")\n",
        "\n",
        "                          try:\n",
        "                            img = Image.open(instance_path).convert(\"RGB\")\n",
        "                            text, bounds = ocr_region(img)\n",
        "\n",
        "                            if language_folder == 'Chinese':\n",
        "                              text = ocr_chinese(instance_path)\n",
        "\n",
        "                            masked_image = mask_image(img, bounds).convert(\"RGB\")\n",
        "                            caption = generate_caption(masked_image)\n",
        "                            explaination = generate_meaning(text, caption)\n",
        "\n",
        "                            result_record = {}\n",
        "                            result_record[\"Meme name\"] = meme_folder\n",
        "                            result_record[\"Language\"] = language_folder\n",
        "                            result_record[\"Instance\"] = instance\n",
        "                            result_record[\"Text\"] = text\n",
        "                            result_record[\"Caption\"] = caption\n",
        "                            result_record[\"Explaination\"] = explaination\n",
        "\n",
        "                            results.append(result_record)\n",
        "\n",
        "                          except Exception as e:\n",
        "                            print(f\"\\t\\tAn error occurred while processing instance {instance} of meme {meme_folder}.\")\n",
        "                            continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kTdHZtDXSZkm",
        "outputId": "91d7dd40-0c37-4ee7-dbe5-8eda8316d143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing meme: Tuxedo Winnie The Pooh      1/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9hml8k.jpg\n",
            "\t\tProcessing instance: 9gldwp.jpg\n",
            "\t\tProcessing instance: 9gfwdv.jpg\n",
            "\t\tProcessing instance: 9h8bl7.jpg\n",
            "\t\tProcessing instance: 9h80me.jpg\n",
            "\t\tProcessing instance: 9go3nh.jpg\n",
            "\t\tProcessing instance: 9gpsto.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115236.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115304.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115324.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115346.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115404.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115422.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115446.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1631368423430.jpg\n",
            "\t\tProcessing instance: 1643205524135.jpg\n",
            "\t\tProcessing instance: 1688441585860.jpg\n",
            "\t\tProcessing instance: 1657887795228.jpg\n",
            "\t\tProcessing instance: 1631444901290.jpg\n",
            "\t\tProcessing instance: 1630840319663.jpg\n",
            "\n",
            "Processing meme: Surprised Pikachu      2/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9c33h5.jpg\n",
            "\t\tProcessing instance: 95ajs4.jpg\n",
            "\t\tProcessing instance: 9d2owr.jpg\n",
            "\t\tProcessing instance: 8lrpby.jpg\n",
            "\t\tProcessing instance: 9a10dw.jpg\n",
            "\t\tProcessing instance: 86dby8.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 194007.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 194034.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 194106.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 194130.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 194221.png\n",
            "\t\tProcessing instance: 419148097_346508041466647_5986461890940735922_n.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1646840663043.jpg\n",
            "\t\tProcessing instance: 1606892507755.jpg\n",
            "\t\tProcessing instance: 1631714528975.jpg\n",
            "\t\tProcessing instance: 1572211434975.jpg\n",
            "\t\tProcessing instance: 1615441406985.jpg\n",
            "\t\tProcessing instance: 1585160887893.jpg\n",
            "\n",
            "Processing meme: Woman yelling at cat      3/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 1726130965119.jpg\n",
            "\t\tProcessing instance: 9gycwg.jpg\n",
            "\t\tProcessing instance: 9eoh1k.jpg\n",
            "\t\tProcessing instance: 9edeaw.jpg\n",
            "\t\tProcessing instance: 9clpmh.jpg\n",
            "\t\tProcessing instance: 97axph.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 115953.png\n",
            "\t\tProcessing instance: 74389973_2434193410013280_686590748929294336_n.jpg\n",
            "\t\tProcessing instance: 72166505_2377832098982745_1267596444215279616_n.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 125821.png\n",
            "\t\tProcessing instance: 71667278_2355605214538767_3665003599219392512_n.jpg\n",
            "\t\tProcessing instance: 69812457_2302737786492177_4076306009834913792_n.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1736539660706.jpg\n",
            "\t\tProcessing instance: 1683559190045.jpg\n",
            "\t\tProcessing instance: 1681364660754.jpg\n",
            "\t\tProcessing instance: 1680569006736.jpg\n",
            "\t\tProcessing instance: 1680540571046.jpg\n",
            "\t\tProcessing instance: 1677983306277.jpg\n",
            "\n",
            "Processing meme: Two Buttons      4/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9gxvkr.jpg\n",
            "\t\tProcessing instance: 9h0yzd.jpg\n",
            "\t\tProcessing instance: 9g9wgo.jpg\n",
            "\t\tProcessing instance: 9gdkqm.jpg\n",
            "\t\tProcessing instance: 9ghvkr.jpg\n",
            "\t\tProcessing instance: 9h4qnr.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 164929.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 164956.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 165033.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 165105.png\n",
            "\t\tProcessing instance: rediger-doc-technique-boutons-meme.jpg\n",
            "\t\tProcessing instance: 8cgmg1ygnk251.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1625019259180.jpg\n",
            "\t\tProcessing instance: 1633542410425.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 173042.png\n",
            "\t\tProcessing instance: 1627483537178.jpg\n",
            "\t\tProcessing instance: 1626426294575.jpg\n",
            "\t\tProcessing instance: 1639228711798.jpg\n",
            "\n",
            "Processing meme: Surprised Joey      5/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 8v5bjr.jpg\n",
            "\t\tProcessing instance: 8qz7v1.jpg\n",
            "\t\tProcessing instance: 7i8934.jpg\n",
            "\t\tProcessing instance: 6ir6c8.jpg\n",
            "\t\tProcessing instance: 6w4vrd.jpg\n",
            "\t\tProcessing instance: 6b9896.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 110945.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 111854.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 112109.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 113925.png\n",
            "\t\tProcessing instance: 134132273_3482655301833747_5003041318434848300_n.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1633382831462.jpg\n",
            "\t\tProcessing instance: 1654349257295.jpg\n",
            "\t\tProcessing instance: 1621578472714.jpg\n",
            "\t\tProcessing instance: 1654751400409.jpg\n",
            "\t\tProcessing instance: 1652548600309.jpg\n",
            "\t\tProcessing instance: 1649541477740.jpg\n",
            "\n",
            "Processing meme: Tom and Jerry swordfight      6/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 99owpz.jpg\n",
            "\t\tProcessing instance: 8nnnm5.jpg\n",
            "\t\tProcessing instance: 92yyyk.jpg\n",
            "\t\tProcessing instance: 97oa5j.jpg\n",
            "\t\tProcessing instance: 6mzpo8.jpg\n",
            "\t\tProcessing instance: 9d734k.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 122346.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 122404.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 122421.png\n",
            "\t\tProcessing instance: 62c5dbbd4d5ce.jpeg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1659058617431.jpg\n",
            "\t\tProcessing instance: 1636711857390.jpg\n",
            "\t\tProcessing instance: 1633336508137.jpg\n",
            "\t\tProcessing instance: 1674218839474.jpg\n",
            "\t\tProcessing instance: 1670926782876.jpg\n",
            "\t\tProcessing instance: 1662645761970.jpg\n",
            "\n",
            "Processing meme: Sweating Bullets      7/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 98v05l.jpg\n",
            "\t\tProcessing instance: 6pi63y.jpg\n",
            "\t\tProcessing instance: 90wyv2.jpg\n",
            "\t\tProcessing instance: 965teo.jpg\n",
            "\t\tProcessing instance: 91vvvg.jpg\n",
            "\t\tProcessing instance: 7vkx86.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: 65911743_2209357625830194_2089166332946808832_n.jpg\n",
            "\t\tProcessing instance: 71182178_2354695764629712_8382187028187447296_n.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 095117.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 095150.png\n",
            "\t\tProcessing instance: Screenshot_23-1-2025_10255_www.instagram.com.jpeg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1659449240371.jpg\n",
            "\t\tProcessing instance: 1655646959576.jpg\n",
            "\t\tProcessing instance: 1612283343199.jpg\n",
            "\t\tProcessing instance: 1683497447163.jpg\n",
            "\t\tProcessing instance: 1598559356008.jpg\n",
            "\t\tProcessing instance: 1657452554980.jpg\n",
            "\n",
            "Processing meme: Types Of Headaches      8/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9h5wot.jpg\n",
            "\t\tProcessing instance: 9ec6i2.jpg\n",
            "\t\tProcessing instance: 9gikbk.jpg\n",
            "\t\tProcessing instance: 9f3t5p.jpg\n",
            "\t\tProcessing instance: 9eu8rf.jpg\n",
            "\t\tProcessing instance: 9d31yi.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 151843.png\n",
            "\t\tProcessing instance: 20231227.jpg\n",
            "\t\tProcessing instance: Fa2H9LpWAAIMiBL.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 152157.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 152249.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1629771482413.jpg\n",
            "\t\tProcessing instance: 1630582363809.jpg\n",
            "\t\tProcessing instance: 1621416092435.jpg\n",
            "\t\tProcessing instance: 1655052674681.jpg\n",
            "\t\tProcessing instance: 1630402350682.jpg\n",
            "\t\tProcessing instance: 1628839464509.jpg\n",
            "\n",
            "Processing meme: Stonks      9/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 8pez1w.jpg\n",
            "\t\tProcessing instance: 8839yw.jpg\n",
            "\t\tProcessing instance: 7tgo9v.jpg\n",
            "\t\tProcessing instance: 7i2zwf.jpg\n",
            "\t\tProcessing instance: 7qo0yg.jpg\n",
            "\t\tProcessing instance: 7eaq2y.jpg\n",
            "\t\tProcessing instance: 7uk7wk.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 182352.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 182448.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 182600.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 182632.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 182734.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 182818.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1651608607136.jpg\n",
            "\t\tProcessing instance: 1642751183364.jpg\n",
            "\t\tProcessing instance: 1615379075079.jpg\n",
            "\t\tProcessing instance: 1597251007622.jpg\n",
            "\t\tProcessing instance: 1647842688959.jpg\n",
            "\t\tProcessing instance: 1628043279130.jpg\n",
            "\n",
            "Processing meme: Unsettled Tom      10/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9h2uzr.jpg\n",
            "\t\tProcessing instance: 984221.jpg\n",
            "\t\tProcessing instance: 90f9co.jpg\n",
            "\t\tProcessing instance: 8dcdls.jpg\n",
            "\t\tProcessing instance: 8dho56.jpg\n",
            "\t\tProcessing instance: 4nckii.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 184041.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 184146.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 184558.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 184718.png\n",
            "\t\tProcessing instance: 60101801_2118080558291235_1062118444201148416_n.jpg\n",
            "\t\tProcessing instance: 54390837_2030428000389825_6587382721322942464_n.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1625754182843.jpg\n",
            "\t\tProcessing instance: 1634960744175.jpg\n",
            "\t\tProcessing instance: 1636757334299.jpg\n",
            "\t\tProcessing instance: 1621402056078.jpg\n",
            "\t\tProcessing instance: 1578375425814.jpg\n",
            "\t\tProcessing instance: 1638017846063.jpg\n",
            "\n",
            "Processing meme: Spiderman pointing at spiderman      11/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9a0fhd.jpg\n",
            "\t\tProcessing instance: 91htbj.jpg\n",
            "\t\tProcessing instance: 967h3f.jpg\n",
            "\t\tProcessing instance: 8sezt0.jpg\n",
            "\t\tProcessing instance: 8r8kek.jpg\n",
            "\t\tProcessing instance: 8i2ihq.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 142558.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 142648.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 142725.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 142900.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 143505.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 143535.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1628733382205.jpg\n",
            "\t\tAn error occurred while processing instance 1628733382205.jpg of meme Spiderman pointing at spiderman.\n",
            "\t\tProcessing instance: 1630929180598.jpg\n",
            "\t\tProcessing instance: 1627958386994.jpg\n",
            "\t\tProcessing instance: 1649510383990.jpg\n",
            "\t\tProcessing instance: 1656464588555.jpg\n",
            "\t\tProcessing instance: 1641882445286.jpg\n",
            "\n",
            "Processing meme: Roll Safe Think About It      12/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9czlis.jpg\n",
            "\t\tProcessing instance: 9cdwm5.jpg\n",
            "\t\tProcessing instance: 9e08tu.jpg\n",
            "\t\tProcessing instance: 96qfsc.jpg\n",
            "\t\tProcessing instance: 90weu4.jpg\n",
            "\t\tProcessing instance: 9cxhhx.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 092006.png\n",
            "\t\tProcessing instance: 2gza57.jpg\n",
            "\t\tProcessing instance: 729b5r.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 092124.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 092148.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 093435.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1665504701427.jpg\n",
            "\t\tProcessing instance: 1659157540800.jpg\n",
            "\t\tProcessing instance: 1619663901939.jpg\n",
            "\t\tProcessing instance: 1611474927493.jpg\n",
            "\t\tProcessing instance: 1668093972379.jpg\n",
            "\t\tProcessing instance: 1658655560853.jpg\n",
            "\n",
            "Processing meme: Spongebob Burning Paper      13/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9dcxcg.jpg\n",
            "\t\tProcessing instance: 9empq5.jpg\n",
            "\t\tProcessing instance: 9d7eaa.jpg\n",
            "\t\tProcessing instance: 8ep66n.jpg\n",
            "\t\tProcessing instance: 97hdfo.jpg\n",
            "\t\tProcessing instance: 987ysi.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 121009.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 121038.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 121120.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 121140.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 121157.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 121221.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1619107892587.jpg\n",
            "\t\tProcessing instance: 1623861591128.jpg\n",
            "\t\tProcessing instance: 1662782578073.jpg\n",
            "\t\tProcessing instance: 1641306989189.jpg\n",
            "\t\tProcessing instance: 1627885287003.jpg\n",
            "\t\tProcessing instance: 1629970991344.jpg\n",
            "\n",
            "Processing meme: Sad Pablo Escobar      14/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 97aidg.jpg\n",
            "\t\tProcessing instance: 9ewryc.jpg\n",
            "\t\tProcessing instance: 9aeu6z.jpg\n",
            "\t\tProcessing instance: 9bm9ah.jpg\n",
            "\t\tProcessing instance: 9bcqrj.jpg\n",
            "\t\tProcessing instance: 923tyq.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: 5t1mml.jpg\n",
            "\t\tProcessing instance: 313400538_656087196056685_6880764827744240504_n.jpg\n",
            "\t\tProcessing instance: 6225e55b0da08.jpeg\n",
            "\t\tProcessing instance: 617af0f223741.jpeg\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 143115.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 143357.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1732352012927.jpg\n",
            "\t\tProcessing instance: 1732351935460.jpg\n",
            "\t\tProcessing instance: 1729668917238.jpg\n",
            "\t\tProcessing instance: 1723561332103.jpg\n",
            "\t\tProcessing instance: 1721885923406.jpg\n",
            "\t\tProcessing instance: 1702288469950.jpg\n",
            "\n",
            "Processing meme: Peter Parker Glasses      15/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 7z3jg1.jpg\n",
            "\t\tProcessing instance: 8faybw.jpg\n",
            "\t\tProcessing instance: 6xvcj9.jpg\n",
            "\t\tProcessing instance: 8flyos.jpg\n",
            "\t\tProcessing instance: 4nhywa.jpg\n",
            "\t\tProcessing instance: 6o8irm.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 093535.png\n",
            "\t\tProcessing instance: 2wbdpx.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 094043.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 094909.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 095408.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1636512665856.jpg\n",
            "\t\tProcessing instance: 1623854450513.jpg\n",
            "\t\tProcessing instance: 1652315837031.jpg\n",
            "\t\tProcessing instance: 1631936657967.jpg\n",
            "\t\tProcessing instance: 1631703584666.jpg\n",
            "\t\tProcessing instance: 1637121283405.jpg\n",
            "\n",
            "Processing meme: My Heart      16/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 8w2vwk.jpg\n",
            "\t\tProcessing instance: 7w6w8b.jpg\n",
            "\t\tProcessing instance: 8vfv0z.jpg\n",
            "\t\tProcessing instance: 4q5hiq.jpg\n",
            "\t\tProcessing instance: 6ip21i.jpg\n",
            "\t\tProcessing instance: 7atwna.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 123059.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 123119.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 123139.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 123204.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 123228.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 123250.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1625544680655.jpg\n",
            "\t\tProcessing instance: 1653799773372.jpg\n",
            "\t\tProcessing instance: 1632806602426.jpg\n",
            "\t\tProcessing instance: 1670160192625.jpg\n",
            "\t\tProcessing instance: 1624005151558.jpg\n",
            "\t\tProcessing instance: 1571471173919.jpg\n",
            "\n",
            "Processing meme: Oh yeah oh no      17/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9h5zvi.jpg\n",
            "\t\tProcessing instance: 967tk8.jpg\n",
            "\t\tProcessing instance: 9de2ut.jpg\n",
            "\t\tProcessing instance: 6g2yse.jpg\n",
            "\t\tProcessing instance: 8wjumr.jpg\n",
            "\t\tProcessing instance: 6rez0w.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 145403.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 145633.png\n",
            "\t\tProcessing instance: 464568658_8433900863375808_5055784847781406414_n.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 150856.png\n",
            "\t\tProcessing instance: w3t3tqjdhe3d1.jpeg\n",
            "\t\tProcessing instance: bya92g9ztunc1.jpeg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1631259028418.jpg\n",
            "\t\tProcessing instance: 1623992111900.jpg\n",
            "\t\tProcessing instance: 1625336672196.jpg\n",
            "\t\tProcessing instance: 1641766066261.jpg\n",
            "\t\tProcessing instance: 1644885277060.jpg\n",
            "\t\tProcessing instance: 1654767139085.jpg\n",
            "\n",
            "Processing meme: Panik Kalm Panik      18/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9hmtmc.jpg\n",
            "\t\tProcessing instance: 9h66yn.jpg\n",
            "\t\tProcessing instance: 9h32g8.jpg\n",
            "\t\tProcessing instance: 9gyttr.jpg\n",
            "\t\tProcessing instance: 9ghkuy.jpg\n",
            "\t\tProcessing instance: 9hpki5.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115741.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115807.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115828.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115847.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115906.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 115926.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1679479347180.jpg\n",
            "\t\tProcessing instance: 1646821688175.jpg\n",
            "\t\tProcessing instance: 1651716170579.jpg\n",
            "\t\tProcessing instance: 1642766793928.jpg\n",
            "\t\tProcessing instance: 1668742328348.jpg\n",
            "\t\tProcessing instance: 1644472300212.jpg\n",
            "\n",
            "Processing meme: Peter Parker Sad and Happy Cry      19/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 8fjoif.jpg\n",
            "\t\tProcessing instance: 79zycz.jpg\n",
            "\t\tProcessing instance: 5rjzub.jpg\n",
            "\t\tProcessing instance: 61k347.jpg\n",
            "\t\tProcessing instance: 6bvjpn.jpg\n",
            "\t\tProcessing instance: 87r7ea.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 153257.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 153329.png\n",
            "\t\tProcessing instance: 474559411_8914577148641508_5924606319498761748_n.jpg\n",
            "\t\tProcessing instance: 110526781_3027116324054316_1694332457735054543_n.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1663456614313.jpg\n",
            "\t\tProcessing instance: 1660323383235.jpg\n",
            "\t\tProcessing instance: 1673006508674.jpg\n",
            "\t\tProcessing instance: 1657460199193.jpg\n",
            "\t\tProcessing instance: 1719534380383.jpg\n",
            "\t\tProcessing instance: 1686678568356.jpg\n",
            "\n",
            "Processing meme: Squidward Window      20/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9gued7.jpg\n",
            "\t\tProcessing instance: 9govye.jpg\n",
            "\t\tProcessing instance: 9ghqi1.jpg\n",
            "\t\tProcessing instance: 979nao.jpg\n",
            "\t\tProcessing instance: 8d6w1h.jpg\n",
            "\t\tProcessing instance: 98km77.jpg\n",
            "\t\tProcessing instance: 7b9g1s.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 123639.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 123702.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 123733.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 124452.png\n",
            "\t\tProcessing instance: E0tbuxuVIAooC94.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1636163049325.jpg\n",
            "\t\tProcessing instance: 1655251961933.jpg\n",
            "\t\tProcessing instance: 1636253068433.jpg\n",
            "\t\tProcessing instance: 1663509203379.jpg\n",
            "\t\tProcessing instance: 1624430641945.jpg\n",
            "\t\tProcessing instance: 1622724826681.jpg\n",
            "\n",
            "Processing meme: Monkey Puppet      21/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9gqwbf.jpg\n",
            "\t\tProcessing instance: 9h5xes.jpg\n",
            "\t\tProcessing instance: 9cr773.jpg\n",
            "\t\tProcessing instance: 9c33pp.jpg\n",
            "\t\tProcessing instance: 9cjdp5.jpg\n",
            "\t\tProcessing instance: 8t9cdi.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 115123.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 115152.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 115222.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 115304.png\n",
            "\t\tProcessing instance: memeinternet-15209.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1630965695747.jpg\n",
            "\t\tProcessing instance: 1630972146487.jpg\n",
            "\t\tProcessing instance: 1615965690189.jpg\n",
            "\t\tProcessing instance: 1632899664880.jpg\n",
            "\t\tProcessing instance: 1666581056847.jpg\n",
            "\t\tProcessing instance: 1621144016185.jpg\n",
            "\n",
            "Processing meme: Leonardo Dicaprio Cheers      22/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9hq1pp.jpg\n",
            "\t\tProcessing instance: 9gfwsb.jpg\n",
            "\t\tProcessing instance: 9djrza.jpg\n",
            "\t\tProcessing instance: 9djf70.jpg\n",
            "\t\tProcessing instance: 99wzln.jpg\n",
            "\t\tProcessing instance: 8w4r93.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 103600.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 103850.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 104056.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 104123.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 104303.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1633354545801.jpg\n",
            "\t\tProcessing instance: 1643644810895.jpg\n",
            "\t\tProcessing instance: 1652420347778.jpg\n",
            "\t\tProcessing instance: 1655413112698.jpg\n",
            "\t\tProcessing instance: 1654525699717.jpg\n",
            "\t\tProcessing instance: 1653547794846.jpg\n",
            "\n",
            "Processing meme: Mr Incredible      23/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9fdq3m.jpg\n",
            "\t\tProcessing instance: 9f1sp7.jpg\n",
            "\t\tProcessing instance: 8zvuoa.jpg\n",
            "\t\tProcessing instance: 95silb.jpg\n",
            "\t\tProcessing instance: 90lkrk.jpg\n",
            "\t\tProcessing instance: 9a1y56.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 174249.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 174323.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 174421.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 174537.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 174730.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 174757.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1635905686242.jpg\n",
            "\t\tProcessing instance: 1635795836423.jpg\n",
            "\t\tProcessing instance: 1631613720983.jpg\n",
            "\t\tProcessing instance: 1652966997193.jpg\n",
            "\t\tProcessing instance: 1660472990741.jpg\n",
            "\t\tProcessing instance: 1648813308511.jpg\n",
            "\n",
            "Processing meme: Hide the Pain Harold      24/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9glqv9.jpg\n",
            "\t\tProcessing instance: 9gyu7u.jpg\n",
            "\t\tProcessing instance: 9fkqtw.jpg\n",
            "\t\tProcessing instance: 9fxiun.jpg\n",
            "\t\tProcessing instance: 9fyxqp.jpg\n",
            "\t\tProcessing instance: 9d6hgd.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 134609.png\n",
            "\t\tProcessing instance: 66939e07aae61.jpeg\n",
            "\t\tProcessing instance: 66841ed444a37.jpeg\n",
            "\t\tProcessing instance: 6092c45984c90.jpeg\n",
            "\t\tProcessing instance: 1634284358427.jpg\n",
            "\t\tProcessing instance: cd8d293c52d0f076287357d5873adb3c.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1736261899591.jpg\n",
            "\t\tProcessing instance: 1733980431256.jpg\n",
            "\t\tProcessing instance: 1733474141394.jpg\n",
            "\t\tProcessing instance: 1733456423605.jpg\n",
            "\t\tProcessing instance: 1733193882472.jpg\n",
            "\t\tProcessing instance: 1732973397511.jpg\n",
            "\n",
            "Processing meme: Is this a pigeon      25/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9ffmup.jpg\n",
            "\t\tProcessing instance: 9dnhwk.jpg\n",
            "\t\tProcessing instance: 9esj7j.jpg\n",
            "\t\tProcessing instance: 9bdpc9.jpg\n",
            "\t\tProcessing instance: 94252f.jpg\n",
            "\t\tProcessing instance: 93bpj2.jpg\n",
            "\t\tProcessing instance: 7rzyuh.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 130740.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 130812.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 130840.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 130939.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 131032.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 131108.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1697917404180.jpg\n",
            "\t\tProcessing instance: 1690524257245.jpg\n",
            "\t\tProcessing instance: 1688628601646.jpg\n",
            "\t\tProcessing instance: 1679587629850.jpg\n",
            "\t\tProcessing instance: 1677835220713.jpg\n",
            "\t\tProcessing instance: 1668931142847.jpg\n",
            "\t\tProcessing instance: 1668782068445.jpg\n",
            "\n",
            "Processing meme: I Bet He's Thinking About Other Women      26/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9gv46k.jpg\n",
            "\t\tProcessing instance: 9gvnv1.jpg\n",
            "\t\tProcessing instance: 9gpplo.jpg\n",
            "\t\tProcessing instance: 9fdqw8.jpg\n",
            "\t\tProcessing instance: 9gez17.jpg\n",
            "\t\tProcessing instance: 9e02of.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 144302.png\n",
            "\t\tProcessing instance: IMG_4405.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 144446.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 144532.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 144640.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 145329.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1734063894368.jpg\n",
            "\t\tProcessing instance: 1727448626910.jpg\n",
            "\t\tProcessing instance: 1716475774331.jpg\n",
            "\t\tProcessing instance: 1719923061988.jpg\n",
            "\t\tProcessing instance: 1696429967205.jpg\n",
            "\t\tProcessing instance: 1696292912712.jpg\n",
            "\n",
            "Processing meme: Futurama Meme      27/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9brttv.jpg\n",
            "\t\tProcessing instance: 9g0cow.jpg\n",
            "\t\tProcessing instance: 9coygp.jpg\n",
            "\t\tProcessing instance: 9eh5lp.jpg\n",
            "\t\tProcessing instance: 8p6c3o.jpg\n",
            "\t\tProcessing instance: 7jhl8j.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 113942.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 114042.png\n",
            "\t\tProcessing instance: futurama-fry-tes-con-ou-juste-stupide.jpg\n",
            "\t\tProcessing instance: futurama-fry-je-ne-sais-pas-je-suis-moche-ou-les-autres-personnes-sont-belles.jpg\n",
            "\t\tProcessing instance: futurama-fry-je-ne-sais-pas-si-mon-chat-dechiquete-ce-jouet-car-il-laime-ou-car-il-le-deteste.jpg\n",
            "\t\tProcessing instance: futurama-fry-je-ne-sais-pas-si-je-suis-malade-ou-si-cest-une-allergie.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1607137165710.jpg\n",
            "\t\tProcessing instance: 1671894803112.jpg\n",
            "\t\tProcessing instance: 1586860361806.jpg\n",
            "\t\tProcessing instance: 1605854307064.jpg\n",
            "\t\tProcessing instance: 1584295811957.jpg\n",
            "\t\tProcessing instance: 1577695767288.jpg\n",
            "\n",
            "Processing meme: Kermit Waiting      28/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 5fuh56.jpg\n",
            "\t\tProcessing instance: 74wka1.jpg\n",
            "\t\tProcessing instance: 4c5nxj.jpg\n",
            "\t\tProcessing instance: 5t9jsv.jpg\n",
            "\t\tProcessing instance: 8vj1hl.jpg\n",
            "\t\tProcessing instance: 7mgr92.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 102214.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 102244.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 102307.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 102327.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 102346.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 102411.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1666267890039.jpg\n",
            "\t\tProcessing instance: 1645023010230.jpg\n",
            "\t\tProcessing instance: 1644942466351.jpg\n",
            "\t\tProcessing instance: 1635346223587.jpg\n",
            "\t\tProcessing instance: 1600114407379.jpg\n",
            "\t\tProcessing instance: 1592497451579.jpg\n",
            "\n",
            "Processing meme: Laughing leonardo      29/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9gldss.jpg\n",
            "\t\tProcessing instance: 9a9v9s.jpg\n",
            "\t\tProcessing instance: 9evw2w.jpg\n",
            "\t\tProcessing instance: 94xozy.jpg\n",
            "\t\tProcessing instance: 4qnsiy.jpg\n",
            "\t\tProcessing instance: 7wb2bc.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: 120426376_3232013003564646_6779215981683351762_n.jpg\n",
            "\t\tProcessing instance: 120552977_3235520259880587_3345638947184338158_n.jpg\n",
            "\t\tProcessing instance: 120062332_3210581149041165_8409175580405347990_n.jpg\n",
            "\t\tProcessing instance: 126292430_3375981595834452_2005422142758050012_n.jpg\n",
            "\t\tProcessing instance: 117336946_3077007512398530_226524151349130391_n.jpg\n",
            "\t\tProcessing instance: 94224551_2804318806334070_1679138758819053568_n.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1724071483784.jpg\n",
            "\t\tProcessing instance: 1697039543892.jpg\n",
            "\t\tProcessing instance: 1670131405834.jpg\n",
            "\t\tProcessing instance: 1661931143854.jpg\n",
            "\t\tProcessing instance: 1652434611057.jpg\n",
            "\t\tProcessing instance: 1652349221525.jpg\n",
            "\n",
            "Processing meme: Mr Bean Waiting      30/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9fw069.jpg\n",
            "\t\tProcessing instance: 9aurkd.jpg\n",
            "\t\tProcessing instance: 9es15c.jpg\n",
            "\t\tProcessing instance: 7zx3x0.jpg\n",
            "\t\tProcessing instance: 8wi94f.jpg\n",
            "\t\tProcessing instance: 75xcfd.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: images.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 121914.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 122005.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 122211.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 122358.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 122538.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1600435179091.jpg\n",
            "\t\tProcessing instance: 1659510412620.jpg\n",
            "\t\tProcessing instance: 1659411319105.jpg\n",
            "\t\tProcessing instance: 1636982706987.jpg\n",
            "\t\tProcessing instance: 1659501982998.jpg\n",
            "\t\tProcessing instance: 1623577314057.jpg\n",
            "\n",
            "Processing meme: Buff Doge vs. Cheems      31/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9gqri9.jpg\n",
            "\t\tProcessing instance: 9gjjie.jpg\n",
            "\t\tProcessing instance: 9g8hmq.jpg\n",
            "\t\tProcessing instance: 8yquxp.jpg\n",
            "\t\tProcessing instance: 8vsj9s.jpg\n",
            "\t\tProcessing instance: 9bczza.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 175525.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 175550.png\n",
            "\t\tProcessing instance: 5f8pee.jpg\n",
            "\t\tProcessing instance: pvf9bkc2l6vd1.jpeg\n",
            "\t\tProcessing instance: 204534384_3959279934171279_5710760958030902892_n.jpg\n",
            "\t\tProcessing instance: 145852114_3569760149789928_2419114841825925753_n.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1625043118455.jpg\n",
            "\t\tProcessing instance: 1632312448129.jpg\n",
            "\t\tProcessing instance: 1622448405163.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 180827.png\n",
            "\t\tProcessing instance: 1625115191616.jpg\n",
            "\t\tProcessing instance: 1660191190474.jpg\n",
            "\n",
            "Processing meme: Expanding Brain      32/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9gochi.jpg\n",
            "\t\tProcessing instance: 9h0dzz.jpg\n",
            "\t\tProcessing instance: 9gkqat.jpg\n",
            "\t\tProcessing instance: 9f2aj7.jpg\n",
            "\t\tProcessing instance: 9gkszp.jpg\n",
            "\t\tProcessing instance: 9d4qf1.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: 5e39b3f9269a5.jpeg\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 104541.png\n",
            "\t\tProcessing instance: 66d95ad6c6f49.jpeg\n",
            "\t\tProcessing instance: 5e35c4fd2e066.jpeg\n",
            "\t\tProcessing instance: 65841938de4ff.jpeg\n",
            "\t\tProcessing instance: 662a964858548.jpeg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1628903819460.jpg\n",
            "\t\tProcessing instance: 1637498817437.jpg\n",
            "\t\tProcessing instance: 1630853305954.jpg\n",
            "\t\tProcessing instance: 1679482018573.jpg\n",
            "\t\tProcessing instance: 1701091994523.jpg\n",
            "\t\tProcessing instance: 1631167212902.jpg\n",
            "\n",
            "Processing meme: Epic Handshake      33/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9he80j.jpg\n",
            "\t\tProcessing instance: 9h70q9.jpg\n",
            "\t\tProcessing instance: 9gi24y.jpg\n",
            "\t\tProcessing instance: 9gd1s8.jpg\n",
            "\t\tProcessing instance: 8xlmab.jpg\n",
            "\t\tProcessing instance: 9fszxd.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 113730.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 113752.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 113810.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 113835.png\n",
            "\t\tProcessing instance: 94975534-2877373382311912-71433878887202816-n-bicubic-960x640.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1628334569168.jpg\n",
            "\t\tProcessing instance: 1624108609154.jpg\n",
            "\t\tProcessing instance: 1624108868715.jpg\n",
            "\t\tProcessing instance: 1652458157387.jpg\n",
            "\t\tProcessing instance: 1678683976166.jpg\n",
            "\t\tProcessing instance: 1672921263735.jpg\n",
            "\n",
            "Processing meme: Distracted boyfriend      34/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: j6t1dz9yvqvyqish4d8c.png\n",
            "\t\tProcessing instance: 481zc5.jpg\n",
            "\t\tProcessing instance: 9e6klo.jpg\n",
            "\t\tProcessing instance: 708c38f6-8960-451d-879c-73e4443c3a62_512x337.jpg\n",
            "\t\tProcessing instance: 71zjl6.jpg\n",
            "\t\tProcessing instance: 9exuck.jpg\n",
            "\t\tProcessing instance: 97nzz5.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: db_fr_1.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 124500.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 124532.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 124610.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 124641.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 124705.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1707235565741.jpg\n",
            "\t\tProcessing instance: 1655536201891.jpg\n",
            "\t\tProcessing instance: 1729844932735.jpg\n",
            "\t\tProcessing instance: 1684065512866.jpg\n",
            "\t\tProcessing instance: 1670924238514.jpg\n",
            "\t\tAn error occurred while processing instance 1670924238514.jpg of meme Distracted boyfriend.\n",
            "\t\tProcessing instance: 1704678307919.jpg\n",
            "\n",
            "Processing meme: Chill Guy      35/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9h0pw3.jpg\n",
            "\t\tProcessing instance: 9hagqk.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 110257.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 110331.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 110441.png\n",
            "\t\tProcessing instance: 9bqvvv.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 105249.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 105332.png\n",
            "\t\tProcessing instance: images.jpg\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 105531.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 105602.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 105630.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: images (1).jpg\n",
            "\t\tProcessing instance: 468264105_8610400442363070_1845100754392764654_n.jpg\n",
            "\t\tProcessing instance: 468324375_8618356414908345_371216039928820728_n.jpg\n",
            "\t\tProcessing instance: 467898864_1085446603085988_4687214333358639803_n.jpg\n",
            "\t\tProcessing instance: 1733629217274.jpg\n",
            "\n",
            "Processing meme: Evil Patrick      36/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 96k4d3.jpg\n",
            "\t\tProcessing instance: 7bep6d.jpg\n",
            "\t\tProcessing instance: 5jr3wg.jpg\n",
            "\t\tProcessing instance: 8f6vt7.jpg\n",
            "\t\tProcessing instance: 86psk6.jpg\n",
            "\t\tProcessing instance: 84hhp5.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 102952.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 103009.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 103028.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 103107.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 103126.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-24 103145.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1627542774878.jpg\n",
            "\t\tProcessing instance: 1623900508998.jpg\n",
            "\t\tProcessing instance: 1616084630066.jpg\n",
            "\t\tProcessing instance: 1612502482379.jpg\n",
            "\t\tProcessing instance: 1591088930827.jpg\n",
            "\t\tProcessing instance: 1612503414317.jpg\n",
            "\n",
            "Processing meme: Clown Applying Makeup      37/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9f5pwc.jpg\n",
            "\t\tProcessing instance: 7egl4c.jpg\n",
            "\t\tProcessing instance: 9gpcfw.jpg\n",
            "\t\tProcessing instance: 95ov0j.jpg\n",
            "\t\tProcessing instance: 9fw1ed.jpg\n",
            "\t\tProcessing instance: 93wrd7.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 110249.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 110421.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 110449.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 110512.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 110532.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 110858.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 112047.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1629768073392.jpg\n",
            "\t\tProcessing instance: 1652544018454.jpg\n",
            "\t\tProcessing instance: 1657969048107.jpg\n",
            "\t\tProcessing instance: 1606954174122.jpg\n",
            "\t\tProcessing instance: 1671355723570.jpg\n",
            "\t\tProcessing instance: 1653351756809.jpg\n",
            "\n",
            "Processing meme: Disaster Girl      38/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9hea7p.jpg\n",
            "\t\tProcessing instance: 9guipw.jpg\n",
            "\t\tProcessing instance: 9ggn0r.jpg\n",
            "\t\tProcessing instance: 88zowd.jpg\n",
            "\t\tProcessing instance: 9fck4h.jpg\n",
            "\t\tProcessing instance: 9fcawy.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 090732.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 090754.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 090822.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 090849.png\n",
            "\t\tProcessing instance: 62299cc85d45d.jpeg\n",
            "\t\tProcessing instance: quand-lalarme-incendie-16e6574f57.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1576048041082.jpg\n",
            "\t\tProcessing instance: 1662900420931.jpg\n",
            "\t\tProcessing instance: 1627869454758.jpg\n",
            "\t\tProcessing instance: 1621416272325.jpg\n",
            "\t\tProcessing instance: 1615972554213.jpg\n",
            "\t\tProcessing instance: 1652341304132.jpg\n",
            "\n",
            "Processing meme: Calculating Meme      39/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 97j56y.jpg\n",
            "\t\tProcessing instance: 80aom0.jpg\n",
            "\t\tProcessing instance: 9cjy9k.jpg\n",
            "\t\tProcessing instance: 7uysko.jpg\n",
            "\t\tProcessing instance: 72amjt.jpg\n",
            "\t\tProcessing instance: 5cf6cj.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 102358.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 102443.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 102706.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-23 102815.png\n",
            "\t\tProcessing instance: 62ef8b22cdcfd.jpeg\n",
            "\t\tProcessing instance: 617e612f21617.jpeg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1627457776682.jpg\n",
            "\t\tAn error occurred while processing instance 1627457776682.jpg of meme Calculating Meme.\n",
            "\t\tProcessing instance: 1602462776304.jpg\n",
            "\t\tProcessing instance: 1719575918769.jpg\n",
            "\t\tProcessing instance: 1676460234218.jpg\n",
            "\t\tAn error occurred while processing instance 1676460234218.jpg of meme Calculating Meme.\n",
            "\t\tProcessing instance: 1632914865755.jpg\n",
            "\t\tAn error occurred while processing instance 1632914865755.jpg of meme Calculating Meme.\n",
            "\t\tProcessing instance: 1627704848755.jpg\n",
            "\t\tAn error occurred while processing instance 1627704848755.jpg of meme Calculating Meme.\n",
            "\n",
            "Processing meme: Drake meme      40/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9gr9y1.jpg\n",
            "\t\tProcessing instance: 9gtfvi.jpg\n",
            "\t\tProcessing instance: 9gy2en.jpg\n",
            "\t\tProcessing instance: 9gof5e.jpg\n",
            "\t\tProcessing instance: 9gri77.jpg\n",
            "\t\tProcessing instance: 9g4t4d.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: 6710b984caeb9.jpeg\n",
            "\t\tProcessing instance: 66e07d326463f.jpeg\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 124056.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 124215.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 124309.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-17 124408.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1736468009891.jpg\n",
            "\t\tProcessing instance: 1736426295106.jpg\n",
            "\t\tProcessing instance: 1736261778891.jpg\n",
            "\t\tProcessing instance: 1736045164451.jpg\n",
            "\t\tProcessing instance: 1735700477981.jpg\n",
            "\t\tProcessing instance: 1733859537470.jpg\n",
            "\n",
            "Processing meme: Boardroom Meeting Suggestion      41/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9h59mh.jpg\n",
            "\t\tProcessing instance: 9ggb6l.jpg\n",
            "\t\tProcessing instance: 9gb6x4.jpg\n",
            "\t\tProcessing instance: 9b8cdl.jpg\n",
            "\t\tProcessing instance: 9dz6tw.jpg\n",
            "\t\tProcessing instance: 9gdm9d.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 112341.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 112427.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 112457.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 112518.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 112612.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 112746.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 112836.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-22 112905.png\n",
            "\t\tProcessing instance: 1635431826814.jpg\n",
            "\t\tProcessing instance: 1672984238878.jpg\n",
            "\t\tProcessing instance: 1648049273907.jpg\n",
            "\t\tProcessing instance: 1718327585660.jpg\n",
            "\n",
            "Processing meme: American Chopper Argument      42/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9dzd3o.jpg\n",
            "\t\tProcessing instance: 9c6bdy.jpg\n",
            "\t\tProcessing instance: 9c6e6s.jpg\n",
            "\t\tProcessing instance: 99n2d8.jpg\n",
            "\t\tProcessing instance: 8gdkhi.jpg\n",
            "\t\tProcessing instance: 909vgz.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 192202.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 192227.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 192301.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 192329.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 192435.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 192502.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1622255884433.jpg\n",
            "\t\tAn error occurred while processing instance 1622255884433.jpg of meme American Chopper Argument.\n",
            "\t\tProcessing instance: 1628458578244.jpg\n",
            "\t\tAn error occurred while processing instance 1628458578244.jpg of meme American Chopper Argument.\n",
            "\t\tProcessing instance: 1627434259250.jpg\n",
            "\t\tProcessing instance: 1620766128392.jpg\n",
            "\t\tAn error occurred while processing instance 1620766128392.jpg of meme American Chopper Argument.\n",
            "\t\tProcessing instance: 1630031873002.jpg\n",
            "\t\tProcessing instance: 1653363269747.jpg\n",
            "\t\tAn error occurred while processing instance 1653363269747.jpg of meme American Chopper Argument.\n",
            "\n",
            "Processing meme: Batman Slapping Robin      43/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9ggez3.jpg\n",
            "\t\tProcessing instance: 9gi1my.jpg\n",
            "\t\tProcessing instance: 9fg2yc.jpg\n",
            "\t\tProcessing instance: 97o17o.jpg\n",
            "\t\tProcessing instance: 9feg8k.jpg\n",
            "\t\tProcessing instance: 9doc9b.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 140127.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 140311.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 140722.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 141215.png\n",
            "\t\tProcessing instance: 9af33daa7a7e8d1fec2616447ec68bab.jpg\n",
            "\t\tProcessing instance: 766e89d89f2ed69ca8c24d7ae3b309ef.jpg\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1735703061848.jpg\n",
            "\t\tProcessing instance: 1735056905456.jpg\n",
            "\t\tProcessing instance: 1734682328961.jpg\n",
            "\t\tProcessing instance: 1733553465962.jpg\n",
            "\t\tProcessing instance: 1729746581335.jpg\n",
            "\t\tProcessing instance: 1728809726267.jpg\n",
            "\n",
            "Processing meme: Anakin Padme 4 Panel      44/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9gzbmf.jpg\n",
            "\t\tProcessing instance: 9f8qhc.jpg\n",
            "\t\tProcessing instance: 9d59te.jpg\n",
            "\t\tProcessing instance: 9c09c4.jpg\n",
            "\t\tProcessing instance: 99r5it.jpg\n",
            "\t\tProcessing instance: 8xbtvl.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 140620.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 140646.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 140718.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 140745.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 140831.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-19 141712.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1625124370018.jpg\n",
            "\t\tProcessing instance: 1625035279324.jpg\n",
            "\t\tProcessing instance: 1630051005389.jpg\n",
            "\t\tProcessing instance: 1629287686641.jpg\n",
            "\t\tProcessing instance: 1634408148569.jpg\n",
            "\t\tProcessing instance: 1627019678493.jpg\n",
            "\n",
            "Processing meme: Brain Before Sleep      45/45\n",
            "\tProcessing language: English\n",
            "\t\tProcessing instance: 9dodrm.jpg\n",
            "\t\tProcessing instance: 8tm5x7.jpg\n",
            "\t\tProcessing instance: 6cxrr3.jpg\n",
            "\t\tProcessing instance: 8wa4cn.jpg\n",
            "\t\tProcessing instance: 976lj5.jpg\n",
            "\t\tProcessing instance: 986hgz.jpg\n",
            "\tProcessing language: French\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 150428.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 150612.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 150646.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 150705.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 150743.png\n",
            "\t\tProcessing instance: Screenshot 2025-01-18 151034.png\n",
            "\tProcessing language: Chinese\n",
            "\t\tProcessing instance: 1629841864236.jpg\n",
            "\t\tProcessing instance: 1630381641764.jpg\n",
            "\t\tProcessing instance: 1630662728903.jpg\n",
            "\t\tProcessing instance: 1637320113453.jpg\n",
            "\t\tProcessing instance: 1633355406148.jpg\n",
            "\t\tProcessing instance: 1652681585173.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_path = \"results.json\"\n",
        "with open(results_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "    json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
        "print(f\"Results saved to {results_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlQxCjZdVJuR",
        "outputId": "ca36e7ff-e027-494d-acfe-b1fde81b7adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to results.json\n"
          ]
        }
      ]
    }
  ]
}